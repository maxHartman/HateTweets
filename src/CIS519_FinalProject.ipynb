{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS519_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxHartman/HateTweets/blob/master/src/CIS519_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI9Y2iEgi7Nn",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing & Load Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQvcJtxo4pKX",
        "colab_type": "text"
      },
      "source": [
        "## Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MECLAoW5byHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# No need to run this again\n",
        "!pip install tweepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocs-RWp0x4mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import matplotlib.pylab as plt\n",
        "import math\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "import string\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU5-QFpbAFj7",
        "colab_type": "text"
      },
      "source": [
        "### RUN THIS WHEN USING HOSTED RUNTIME:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_0rzYssh1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fp = 'drive/Shared drives/CIS 519 Project/code/datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdrKNbMGAPcr",
        "colab_type": "text"
      },
      "source": [
        "### RUN THIS WHEN USING A LOCAL RUNTIME:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIZY13AfAD5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp = '~/Desktop/datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYrSlPFP3TeZ",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yqkzVgI3aLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NAME OPTIONS:\n",
        "# \"acl_web\"\n",
        "# \"crowd_flower\"\n",
        "# \"data_world\"\n",
        "# \"harassment\"\n",
        "# \"olid\"\n",
        "# \"social_commentary\"\n",
        "\n",
        "datasets = set([\n",
        "                \"acl_web\",\n",
        "                \"crowd_flower\", \n",
        "                \"data_world\", \n",
        "                \"harassment\",\n",
        "                \"olid\",                \n",
        "                \"social_com\"])\n",
        "\n",
        "file_name = '/original_data'\n",
        "\n",
        "def load_dataset(data_name, file_name=file_name, file_type='.tsv'):\n",
        "    delimiter_map = {'.csv' : ',',\n",
        "                     '.tsv' : '\\t',\n",
        "                    }\n",
        "    data_path = fp + data_name + file_name + file_type\n",
        "\n",
        "    if data_name not in datasets:\n",
        "       raise ValueError('Argument is not name of an available dataset.')\n",
        "       return None\n",
        "\n",
        "    elif data_name == 'acl_web':\n",
        "        return NotImplementedError('%s dataset has not been implemented to load yet' % data_name)\n",
        "    \n",
        "    elif data_name == 'crowd_flower':\n",
        "        use_cols = [0, 1, 2]\n",
        "        col_headers = [\"raw_tweet\", \"code\", \"code_count\"] \n",
        "        header_val = None\n",
        "        idx_col = None\n",
        "\n",
        "    elif data_name == 'data_world':\n",
        "        use_cols = [0, 1, 2, 5, 6]\n",
        "        col_headers = [\"index\", \"coded_count\", \"hate_speech_count\", \"class\", \"raw_tweet\"]\n",
        "        header_val = 0\n",
        "        idx_col = 0\n",
        "\n",
        "    elif data_name == 'harassment':\n",
        "        use_cols = [0, 1, 2]\n",
        "        col_headers = [\"index\", \"code\", \"raw_tweet\"]\n",
        "        header_val = 0\n",
        "        idx_col = 0\n",
        "\n",
        "    elif data_name == 'olid':\n",
        "        use_cols = [0, 1, 2, 3, 4]\n",
        "        col_headers = [\"index\", \"raw_tweet\", \"subtask_a\", \"subtask_b\", \"subtask_c\"]\n",
        "        header_val = 0\n",
        "        idx_col = 0\n",
        "\n",
        "    elif data_name == 'social_com':\n",
        "        return NotImplementedError('%s dataset has not been implemented to load yet' % data_name)\n",
        "    \n",
        "    df = pd.read_csv(data_path, delimiter=delimiter_map[file_type], index_col=idx_col, \n",
        "                     header=header_val, usecols=use_cols, names=col_headers, encoding='latin-1')\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HDkF7GhgbeF",
        "colab_type": "text"
      },
      "source": [
        "## Data Parsing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWLLe0d_ghdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_acl_web(df):\n",
        "    return NotImplementedError('dataset has not been implemented to parse yet')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqWumjrwglk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_crowd_flower(df):\n",
        "    df['is_hate_speech'] = df['code'].apply({'spam': 0, \n",
        "                                             'hateful': 1,\n",
        "                                             'abusive': 1,\n",
        "                                             'normal': 0}\n",
        "                                            .get)\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoDO-RbJgmuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_data_world(df):\n",
        "    \"\"\"\n",
        "    class = class label for majority of CF users.\n",
        "          0 - hate speech,\n",
        "          1 - offensive language,\n",
        "          2 - neither\n",
        "    \"\"\"\n",
        "\n",
        "    df['is_hate_speech'] = df['class'].apply({1: 0,\n",
        "                                              0: 1, \n",
        "                                              2: 0}\n",
        "                                             .get)\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHQhElD2gs7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_harassment(df):\n",
        "    df['is_hate_speech'] = df['code'].apply({'H': 1, \n",
        "                                             'N': 0}\n",
        "                                            .get)\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVqbdMovg8He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_olid(df):\n",
        "    df['subtask_a'] = df['subtask_a'].apply({'OFF': 1, \n",
        "                                             'NOT': 0}\n",
        "                                            .get)\n",
        "    df['subtask_b'] = df['subtask_b'].apply({'TIN': 1, \n",
        "                                             'UNT': 0}\n",
        "                                            .get)\n",
        "    df['subtask_c'] = df['subtask_c'].apply({'IND': 1, \n",
        "                                             'GRP': 1, \n",
        "                                             'OTH': 0}\n",
        "                                            .get)\n",
        "    df['is_hate_speech'] = df[['subtask_a', 'subtask_b', 'subtask_c']].sum(axis=1)\n",
        "    df['is_hate_speech'] = df['is_hate_speech'].apply({3: 1, \n",
        "                                                       2: 0, \n",
        "                                                       1: 0, \n",
        "                                                       0: 0}\n",
        "                                                      .get)\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N6FF-kfhTDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_social_com(df):\n",
        "    return NotImplementedError('dataset has not been implemented to parse yet')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSesaxochBdi",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc_LnSluNgH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_dataframe(df):\n",
        "    replace_with_empty = '@\\S+|&#|RT(\\s*)|http(s*)://\\S+|[^A-Za-z ]+'\n",
        "    replace_with_space = '\\s...\\s'\n",
        "\n",
        "    df['cleaned_tweet'] = df['raw_tweet'].replace(regex=True, to_replace=r'@\\S+', value=r'')  # removes tweeting at someone\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'\\s...\\s', value=r' ')  # turns ... into just a space\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'&#', value=r'')  # for some reason &'s show up before hashtags, so remove those specific &s\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'RT(\\s*)', value=r'')  # remove the RT that comes before the retweet\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'http(s*)://\\S+', value=r'')  # remove any links to websites\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'[^A-Za-z ]+',value=r'')  # remove any non letter or space\n",
        "    df['cleaned_tweet'] = df['cleaned_tweet'].str.lower() # put it all to lower case\n",
        "    return  df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfzNJNUDiaA6",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test Set Generation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbM_EIR01FOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_test(df, train_pct):\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    train_cutoff = math.floor(train_pct * len(df))\n",
        "    train, test = df[:train_cutoff], df[train_cutoff:]\n",
        "    return train, test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqDUcbgIh7Wh",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvE84MHmjmlP",
        "colab_type": "text"
      },
      "source": [
        "## Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cRvjPWAXC6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_crowd_flower = load_dataset('crowd_flower')\n",
        "df_data_world = load_dataset('data_world')\n",
        "df_harassment = load_dataset('harassment')\n",
        "df_olid = load_dataset('olid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VHAsdBrioZ1",
        "colab_type": "text"
      },
      "source": [
        "## Clean & Parse Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my07fvxjkP-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_cols = [\"is_hate_speech\", \"cleaned_tweet\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_buCpZjO7Bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_crowd_flower_cleaned = clean_dataframe(parse_crowd_flower(df_crowd_flower))[desired_cols]\n",
        "df_data_world_cleaned = clean_dataframe(parse_data_world(df_data_world))[desired_cols]\n",
        "df_harassment_cleaned = clean_dataframe(parse_harassment(df_harassment))[desired_cols]\n",
        "df_olid_cleaned = clean_dataframe(parse_olid(df_olid))[desired_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDs4LVJvoRkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_crowd_flower_cleaned.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYVJtLqPnu3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data_world_cleaned.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0V3vcuFAIf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_harassment_cleaned.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW96Ns0snxlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_olid_cleaned.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX4xZyiLjz1e",
        "colab_type": "text"
      },
      "source": [
        "## Make Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roWR2Yvgmq6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PERCENTAGE = 0.80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVklQZl177FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_train, cf_test = make_train_test(df_crowd_flower_cleaned, TRAIN_PERCENTAGE)\n",
        "dw_train, dw_test = make_train_test(df_data_world_cleaned, TRAIN_PERCENTAGE)\n",
        "harass_train, harass_test = make_train_test(df_harassment_cleaned, TRAIN_PERCENTAGE)\n",
        "olid_train, olid_test = make_train_test(df_olid_cleaned, TRAIN_PERCENTAGE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "powMfxnJkX0C",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaR9yn00kcU7",
        "colab_type": "text"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzaPRGIg3RqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    text = \" \".join(text.split())\n",
        "    buffer = \"\"\n",
        "    tokens = []\n",
        "    for c in text:\n",
        "        if c != ' ' and c not in string.punctuation:\n",
        "            buffer+=c\n",
        "        elif c != ' ' and c in string.punctuation:\n",
        "            if len(buffer) != 0: tokens.append(buffer)\n",
        "            tokens.append(c)\n",
        "            buffer = \"\"\n",
        "        else:\n",
        "            if len(buffer) != 0: tokens.append(buffer)\n",
        "            buffer = \"\"\n",
        "    if len(buffer) != 0: tokens.append(buffer)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90FemdrZTvFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_examples_from_df(dframe, row_name, label_name):\n",
        "    D = []\n",
        "    y = []\n",
        "    for idx, row in dframe.iterrows():\n",
        "        d = row[row_name] \n",
        "        label = row[label_name]\n",
        "        tokens = tokenize(d)\n",
        "        D.append(tokens)\n",
        "        y.append(label)\n",
        "    return D, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kapGHUyoBs-",
        "colab_type": "text"
      },
      "source": [
        "# Doc2Vec Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk24qJwRqp-b",
        "colab_type": "text"
      },
      "source": [
        "## Doc2Vec Vector Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTR7p7udqwjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: Our tokenized document list, tag prefix for labeling (either \"TRAIN\" or \"TEST\")\n",
        "# Returns tagged list of documents for Doc2Vec model to use\n",
        "def tag_docs(D,tag_prefix):\n",
        "    tagged = []\n",
        "    for idx, tweet in enumerate(D):\n",
        "        tag = tag_prefix + '_' + str(idx)\n",
        "        tagged.append(TaggedDocument(tweet, [tag]))\n",
        "    return tagged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSEXKCohrQBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: Doc2Vec model, data set (should use validation data here probably)\n",
        "# Does not return anything, just trains the model and tunes params\n",
        "def train_doc2vec(model,tagged_docs):\n",
        "    for epoch in range(30):\n",
        "        model.train(utils.shuffle([x for x in tagged_docs]), total_examples=len(tagged_docs), epochs=1)\n",
        "        model.alpha -= 0.002\n",
        "        model.min_alpha = model.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehl1XqucrPrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: Doc2Vec model, length of example vectors, tag of either \"TRAIN\" or \"TEST\"\n",
        "# Returns a np matrix of document vectors, to input into Logistic Regression classifier\n",
        "def get_vectors(model, vector_length, tag_type):\n",
        "    vectors = np.zeros((model.corpus_count, vector_length))\n",
        "    for i in range(model.corpus_count):\n",
        "        prefix = tag_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlXHxfgq874_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Doc2Vec Neural Nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slJayfOq8_zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FF NETWORK MODEL  \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(100,100)\n",
        "        self.l2 = torch.nn.Linear(100,25)\n",
        "        self.l3 = torch.nn.Linear(25,1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out1 = self.l1(x)\n",
        "        out2 = self.l2(out1)\n",
        "        out3 = self.l3(F.relu(out2))\n",
        "        y_pred = self.sigmoid(out3)\n",
        "        return y_pred\n",
        "\n",
        "# CNN MODEL\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1,100,kernel_size=3)\n",
        "        self.conv2 = torch.nn.Conv2d(100,8,kernel_size=3)\n",
        "        self.l1 = torch.nn.Linear(288,1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out1 = F.relu(self.conv1(x))\n",
        "        out2 = F.relu(self.conv2(out1))\n",
        "        # reshape\n",
        "        batch_size = out2.size(0)\n",
        "        out2 = out2.view(batch_size,-1)\n",
        "        y_pred = self.sigmoid(self.l1(out2))\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfI0JQTYn8ph",
        "colab_type": "text"
      },
      "source": [
        "## Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3swZMCf9Ypo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model,criterion,optimizer,num_epochs,X,y):\n",
        "    # initialize weights and bias\n",
        "    for m in model.modules():\n",
        "        if isinstance(m,torch.nn.Linear):\n",
        "            torch.nn.init.normal(m.weight,mean=0,std=0.1)\n",
        "            torch.nn.init.constant(m.bias,0.1)\n",
        "        if isinstance(m, torch.nn.Conv2d):\n",
        "            torch.nn.init.normal(m.weight,mean=0,std=0.1)\n",
        "    \n",
        "    best_acc = -1\n",
        "    f1 = -1\n",
        "    # train model\n",
        "    for epoch in range(num_epochs):\n",
        "        y_pred = model(X)\n",
        "        loss = criterion(y_pred,y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        acc,_ = compute_NN_accuracy(y_pred,y)\n",
        "        if acc > best_acc:\n",
        "          best_acc = acc\n",
        "          f1 = calculate_NN_f1(y_pred,y)\n",
        "    \n",
        "    return best_acc,f1 # training accuracy after last epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7dHwk43oGxw",
        "colab_type": "text"
      },
      "source": [
        "# TFIDF Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HSBUuT43a5w",
        "colab_type": "text"
      },
      "source": [
        "## TFIDF Feature Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpWq-aExFjZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vocabulary(D):\n",
        "    vocab = set()\n",
        "    vocab.add(\"<unk>\")\n",
        "    seen = set() \n",
        "    for doc in D:\n",
        "        for t in doc:\n",
        "            if t in seen:\n",
        "                vocab.add(t)\n",
        "            else:\n",
        "                seen.add(t) # add to seen set when we see it first time, when we encounter again we add to vocab\n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0igjWZxL4-Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_idf(D, vocab):\n",
        "    unk = \"<unk>\"\n",
        "    numerator = len(D)\n",
        "    idf = {v:0 for v in vocab}\n",
        "    for doc in D:\n",
        "        doc = set(doc)\n",
        "        unk_used = False\n",
        "        for t in doc:\n",
        "            if t in vocab:\n",
        "                idf[t] += 1\n",
        "            elif not(unk_used):\n",
        "                idf[unk] += 1\n",
        "                unk_used = True\n",
        "    for feat in idf.keys():\n",
        "        idf[feat] = math.log(numerator/idf[feat])\n",
        "    return idf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW-KI7Yd3h2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFIDFFeaturizer(object):\n",
        "    def __init__(self, idf):\n",
        "        self.idf = idf\n",
        "    \n",
        "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
        "        unk = \"<unk>\"\n",
        "        doc_dict = {token:0 for token in vocab}\n",
        "        for t in doc:\n",
        "            if t in vocab:\n",
        "                doc_dict[t] = doc_dict.get(t,0)+1\n",
        "            else:\n",
        "                doc_dict[unk] = doc_dict.get(unk,0)+1\n",
        "        \n",
        "        for token in doc_dict.keys():\n",
        "            doc_dict[token] *= self.idf[token]\n",
        "        \n",
        "        return doc_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYao2bgQXsJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_features(D, featurizer, vocab): \n",
        "    X = []\n",
        "    for doc in D: \n",
        "        X.append(featurizer.convert_document_to_feature_dictionary(doc, vocab))\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bZMjf9L4EaR",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZjT9VlOoV0p",
        "colab_type": "text"
      },
      "source": [
        "### TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W03QceYx4Hhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_f1(y_gold, y_model):\n",
        "    num_pred_positive = 1e-5\n",
        "    num_positive = 1e-5\n",
        "    for label in y_model:\n",
        "        if label == 1:\n",
        "            num_pred_positive += 1 # count total predicted num of positives\n",
        "    for label in y_gold:\n",
        "        if label == 1:\n",
        "            num_positive += 1 # count total actual num of positives\n",
        "    num_true = sum(int((y1 == 1 and y2 == 1)) for y1,y2 in list(zip(y_gold,y_model))) # total true predicted positives\n",
        "    precision = num_true / num_pred_positive\n",
        "    recall = num_true / num_positive\n",
        "    F1 = 2*(precision*recall)/(precision+recall+1e-5)\n",
        "    return F1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO2Sa2JPnRAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(y_pred, y_gold):\n",
        "    num_correct = 0\n",
        "    num_examples = len(y_gold)\n",
        "    for i in range(num_examples):\n",
        "        if y_pred[i] == y_gold[i]:\n",
        "            num_correct += 1\n",
        "    return num_correct/num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k91y4ZdEoYiO",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5aIQTd99ouk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_NN_accuracy(y_pred,y_true):\n",
        "    num_correct = 0\n",
        "    num_instances = y_true.size(0)\n",
        "    predictions = []\n",
        "    for i in range(num_instances):\n",
        "        curr_pred = y_pred[i][0]\n",
        "        curr_true = y_true[i][0]\n",
        "        y_est = 1 if curr_pred > 0.5 else 0\n",
        "        predictions.append(y_est)\n",
        "        if y_est == curr_true:\n",
        "            num_correct += 1\n",
        "    return (num_correct / num_instances),predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyDmP7a-ROdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_NN_f1(y_pred, y_true):\n",
        "    num_pred_positive = 1e-5\n",
        "    num_positive = 1e-5\n",
        "    num_true = 1e-5\n",
        "    num_instances = y_true.size(0)\n",
        "    for i in range(num_instances):\n",
        "      curr_pred = y_pred[i][0]\n",
        "      curr_true = y_true[i][0]\n",
        "      y_est = 1 if curr_pred > 0.5 else 0\n",
        "      if y_est == 1:\n",
        "        num_pred_positive += 1 # count total predicted num of positives\n",
        "      if curr_true == 1:\n",
        "        num_positive += 1\n",
        "      if curr_true == 1 and y_est == 1:\n",
        "        num_true += 1 # count total true predicted positives\n",
        "    \n",
        "    precision = num_true / num_pred_positive\n",
        "    recall = num_true / num_positive\n",
        "    F1 = 2*(precision*recall)/(precision+recall+1e-5)\n",
        "    return F1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cojJha-KpZIA",
        "colab_type": "text"
      },
      "source": [
        "## Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqtgPNmkZphY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE COLORMAP\n",
        "N = 256\n",
        "vals = np.ones((N, 4))\n",
        "vals[:, 0] = np.linspace(0.113, 1, N)\n",
        "vals[:, 1] = np.linspace(0.631, 1, N)\n",
        "vals[:, 2] = np.linspace(0.953, 1, N)\n",
        "newcmp = ListedColormap(vals[::-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppC2LMjApe2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs: true labels, predicted labels, matrix title, matrix colormap\n",
        "# Returns the figure, shows the figure automatically when called\n",
        "def plot_confusion_matrix(y_true,y_pred,title,cmap):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.set(title=title,ylabel='True Label',xlabel='Predicted Label')\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt), fontweight='bold',\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "    return ax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwp9p5sNWizB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: list of F1 scores, list of datasets corresponding to F1 scores, graph title\n",
        "# Returns graph, must call plt.show() after run to show the graph\n",
        "def plot_scores(f1_scores,data_titles,title):\n",
        "    TEAL = (0.113, 0.631, 0.953, 1.0)\n",
        "    idx = np.arange(len(data_titles)) # how many different datasets are we comparing?\n",
        "    plt.ylim((0.0,1.0))\n",
        "    plt.bar(idx,f1_scores,width=0.4,color=TEAL) # plot bar for each test and its F1 score\n",
        "    plt.xlabel('Test Set')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title(title)\n",
        "    plt.xticks(idx, data_titles, fontsize=5, rotation=45)\n",
        "    for i,v in enumerate(f1_scores):\n",
        "        plt.text(i,v+0.01,str(v), color=TEAL, ha='center', fontweight='bold')\n",
        "    return plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV89MYyU4lJD",
        "colab_type": "text"
      },
      "source": [
        "## Run TFIDF-Features Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0nTNI9YKdeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN\n",
        "\n",
        "# GET TOKENIZED DATA AND VOCAB\n",
        "D_train,y_train = construct_examples_from_df(cf_train.sample(10000),\"cleaned_tweet\", \"is_hate_speech\")\n",
        "vocab = get_vocabulary(D_train)\n",
        "\n",
        "# GET TFIDF-FEATURIZED EXAMPLES\n",
        "tfidf = TFIDFFeaturizer(compute_idf(D_train,vocab))\n",
        "X_train = convert_to_features(D_train,tfidf,vocab)\n",
        "\n",
        "# SVM CLASSIFIER\n",
        "vectorizer = DictVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "svm = LinearSVC(loss='hinge',max_iter=10000)\n",
        "svm.fit(X_train_vect, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IryprMSM0yf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST\n",
        "\n",
        "D_test,y_test = construct_examples_from_df(cf_test,\"cleaned_tweet\", \"is_hate_speech\")\n",
        "X_test = convert_to_features(D_test,tfidf,vocab)\n",
        "y_pred_test = svm.predict(vectorizer.fit_transform(X_test))\n",
        "\n",
        "# EVAULATE F1 SCORE, ACCURACY, CONFUSION MATRIX OF TESTING DATA\n",
        "f1_test = calculate_f1(y_test,y_pred_test)\n",
        "acc_test = compute_accuracy(y_pred_test,y_test)\n",
        "plot_confusion_matrix(y_test,y_pred_test,title=\"Training Data 1\", cmap=newcmp)\n",
        "print(f1_test)\n",
        "print(acc_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79MwkG1qdwt",
        "colab_type": "text"
      },
      "source": [
        "## Run Doc2Vec Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9vxCK01qiwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INITIALIZE DOC2VEC, CREATE VECTORS\n",
        "\n",
        "# GET TOKENIZED DATA, TAG DATA\n",
        "D_train,y_train = construct_examples_from_df(harass_train, \"cleaned_tweet\", \"is_hate_speech\")\n",
        "tagged_docs = tag_docs(D_train,\"TRAIN\")\n",
        "\n",
        "# INITIALIZE DOC2VEC MODEL\n",
        "doc_model = Doc2Vec(dm=0, vector_size=100, window=7, negative=5, min_count=2, alpha=0.1)\n",
        "doc_model.build_vocab([x for x in tqdm(tagged_docs)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M2lLBabRCsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAINING\n",
        "\n",
        "# TRAIN MODEL, VECTORIZE DATA\n",
        "doc_model.train(utils.shuffle([x for x in tagged_docs]), total_examples=len(tagged_docs), epochs=15)\n",
        "X_train_vectors = get_vectors(doc_model,100,\"TRAIN\")\n",
        "X_train_vectors = X_train_vectors.reshape([len(D_train), 1, 10, 10])\n",
        "X_train_tensor = torch.from_numpy(X_train_vectors)\n",
        "X_train_tensor = X_train_tensor.float()\n",
        "y_train_tensor = torch.FloatTensor(y_train)\n",
        "y_train_tensor = y_train_tensor.view(y_train_tensor.size(0),-1)\n",
        "\n",
        "# LOGISITIC REGRESSION CLASSIFIER\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(X_train_vectors, y_train)\n",
        "logreg = logreg.fit(X_train_vectors, y_train)\n",
        "y_pred = logreg.predict(X_train_vectors)\n",
        "\n",
        "# EVAULATE F1 SCORE, ACCURACY, CONFUSION MATRIX (FOR LOGISTIC REGRESSION)\n",
        "f1 = calculate_f1(y_train,y_pred)\n",
        "acc = compute_accuracy(y_pred,y_train)\n",
        "plot_confusion_matrix(y_train,y_pred,title=\"Training Data 1\", cmap=newcmp)\n",
        "print(f1)\n",
        "print(acc)\n",
        "\n",
        "# CONVOLUTIONAL NEURAL NET CLASSIFIER\n",
        "NN_model = Net()\n",
        "LCE_criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(NN_model.parameters(),lr=0.01)\n",
        "num_epochs = 100\n",
        "NN_acc,NN_f1 = train_model(NN_model,LCE_criterion,optimizer,num_epochs,X_train_tensor,y_train_tensor)\n",
        "\n",
        "print(NN_acc)\n",
        "print(NN_f1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NoSEWzWLeOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TESTING\n",
        "\n",
        "# GET TOKENIZED DATA, TAG DATA\n",
        "D_test,y_test = construct_examples_from_df(harass_test, \"cleaned_tweet\", \"is_hate_speech\")\n",
        "tagged_docs_test = tag_docs(D_test,\"TEST\")\n",
        "\n",
        "# INITIALIZE DOC2VEC MODEL\n",
        "doc_test_model = Doc2Vec(dm=0, vector_size=100, window=7, negative=5, min_count=2, alpha=0.1)\n",
        "doc_test_model.build_vocab([x for x in tqdm(tagged_docs_test)])\n",
        "doc_test_model.train(utils.shuffle([x for x in tagged_docs_test]), total_examples=len(tagged_docs_test), epochs=15)\n",
        "\n",
        "# LOGISTIC REGRESSION\n",
        "X_test_vectors = get_vectors(doc_test_model,100,\"TEST\")\n",
        "y_pred_test = logreg.predict(X_test_vectors)\n",
        "f1 = calculate_f1(y_test,y_pred_test)\n",
        "acc = compute_accuracy(y_pred_test,y_test)\n",
        "plot_confusion_matrix(y_test,y_pred_test,title=\"Training Data 1\", cmap=newcmp)\n",
        "\n",
        "print(f1)\n",
        "print(acc)\n",
        "\n",
        "# NEURAL NET\n",
        "X_train_vectors = X_train_vectors.reshape([len(D_test), 1, 10, 10])\n",
        "X_test_tensor = torch.from_numpy(X_test_vectors)\n",
        "X_test_tensor = X_test_tensor.float()\n",
        "y_test_tensor = torch.FloatTensor(y_test)\n",
        "y_test_tensor = y_test_tensor.view(y_test_tensor.size(0),-1)\n",
        "test_output = NN_model(X_test_tensor)\n",
        "acc_test,predictions = compute_NN_accuracy(test_output,y_test_tensor)\n",
        "f1_test = calculate_NN_f1(test_output,y_test_tensor)\n",
        "plot_confusion_matrix(y_test,predictions,\"DataWorld Test\",cmap=newcmp)\n",
        "\n",
        "print(acc_test)\n",
        "print(f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}