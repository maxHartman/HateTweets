{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS519_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxHartman/HateTweets/blob/master/src/CIS519_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI9Y2iEgi7Nn",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing & Load Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQvcJtxo4pKX",
        "colab_type": "text"
      },
      "source": [
        "## Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocs-RWp0x4mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import matplotlib.pylab as plt\n",
        "import math\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "import string\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU5-QFpbAFj7",
        "colab_type": "text"
      },
      "source": [
        "### Hosted Runtime Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_0rzYssh1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fp = 'drive/Shared drives/CIS 519 Project/code/datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdrKNbMGAPcr",
        "colab_type": "text"
      },
      "source": [
        "### Local Runtime Configuration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIZY13AfAD5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp = '~/Desktop/datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYrSlPFP3TeZ",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yqkzVgI3aLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "NAME OPTIONS:\n",
        "\"acl_web\"\n",
        "\"crowd_flower\"\n",
        "\"data_world\"\n",
        "\"harassment\"\n",
        "\"olid\"\n",
        "\"social_commentary\"\n",
        "\"\"\"\n",
        "\n",
        "datasets = set([\n",
        "                \"acl_web\",\n",
        "                \"crowd_flower\", \n",
        "                \"data_world\", \n",
        "                \"harassment\",\n",
        "                \"olid\",                \n",
        "                \"social_com\"])\n",
        "\n",
        "file_name = '/original_data'\n",
        "\n",
        "def load_dataset(data_name, file_name=file_name, file_type='.tsv'):\n",
        "    delimiter_map = {'.csv' : ',',\n",
        "                     '.tsv' : '\\t',\n",
        "                    }\n",
        "    data_path = fp + data_name + file_name + file_type\n",
        "\n",
        "    if data_name not in datasets:\n",
        "       raise ValueError('Argument is not name of an available dataset.')\n",
        "       return None\n",
        "\n",
        "    elif data_name == 'acl_web':\n",
        "        return NotImplementedError('%s dataset has not been implemented to load yet' % data_name)\n",
        "    \n",
        "    elif data_name == 'crowd_flower':\n",
        "        use_cols = [0, 1, 2]\n",
        "        col_headers = [\"raw_tweet\", \"code\", \"code_count\"] \n",
        "        header_val = None\n",
        "        idx_col = None\n",
        "\n",
        "    elif data_name == 'data_world':\n",
        "        use_cols = [0, 1, 2, 5, 6]\n",
        "        col_headers = [\"index\", \"coded_count\", \"hate_speech_count\", \"class\", \"raw_tweet\"]\n",
        "        header_val = 0\n",
        "        idx_col = 0\n",
        "\n",
        "    elif data_name == 'harassment':\n",
        "        use_cols = [0, 1, 2]\n",
        "        col_headers = [\"index\", \"code\", \"raw_tweet\"]\n",
        "        header_val = 0\n",
        "        idx_col = 0\n",
        "\n",
        "    elif data_name == 'olid':\n",
        "        use_cols = [0, 1, 2, 3, 4]\n",
        "        col_headers = [\"index\", \"raw_tweet\", \"subtask_a\", \"subtask_b\", \"subtask_c\"]\n",
        "        header_val = 0\n",
        "        idx_col = 0\n",
        "\n",
        "    elif data_name == 'social_com':\n",
        "        return NotImplementedError('%s dataset has not been implemented to load yet' % data_name)\n",
        "    \n",
        "    df = pd.read_csv(data_path, delimiter=delimiter_map[file_type], index_col=idx_col, \n",
        "                     header=header_val, usecols=use_cols, names=col_headers, encoding='latin-1')\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HDkF7GhgbeF",
        "colab_type": "text"
      },
      "source": [
        "## Data Parsing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWLLe0d_ghdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_acl_web(df):\n",
        "    return NotImplementedError('dataset has not been implemented to parse yet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqWumjrwglk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_crowd_flower(df):\n",
        "    df['is_hate_speech'] = df['code'].apply({'spam': 0, \n",
        "                                             'hateful': 1,\n",
        "                                             'abusive': 1,\n",
        "                                             'normal': 0}\n",
        "                                            .get)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoDO-RbJgmuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_data_world(df):\n",
        "    \"\"\"\n",
        "    class = class label for majority of CF users.\n",
        "          0 - hate speech,\n",
        "          1 - offensive language,\n",
        "          2 - neither\n",
        "    \"\"\"\n",
        "\n",
        "    df['is_hate_speech'] = df['class'].apply({1: 0,\n",
        "                                              0: 1, \n",
        "                                              2: 0}\n",
        "                                             .get)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHQhElD2gs7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_harassment(df):\n",
        "    df['is_hate_speech'] = df['code'].apply({'H': 1, \n",
        "                                             'N': 0}\n",
        "                                            .get)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVqbdMovg8He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_olid(df):\n",
        "    df['subtask_a'] = df['subtask_a'].apply({'OFF': 1, \n",
        "                                             'NOT': 0}\n",
        "                                            .get)\n",
        "    df['subtask_b'] = df['subtask_b'].apply({'TIN': 1, \n",
        "                                             'UNT': 0}\n",
        "                                            .get)\n",
        "    df['subtask_c'] = df['subtask_c'].apply({'IND': 1, \n",
        "                                             'GRP': 1, \n",
        "                                             'OTH': 0}\n",
        "                                            .get)\n",
        "    df['is_hate_speech'] = df[['subtask_a', 'subtask_b', 'subtask_c']].sum(axis=1)\n",
        "    df['is_hate_speech'] = df['is_hate_speech'].apply({3: 1, \n",
        "                                                       2: 0, \n",
        "                                                       1: 0, \n",
        "                                                       0: 0}\n",
        "                                                      .get)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N6FF-kfhTDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_social_com(df):\n",
        "    return NotImplementedError('dataset has not been implemented to parse yet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSesaxochBdi",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc_LnSluNgH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_dataframe(df):\n",
        "    replace_with_empty = '@\\S+|&#|RT(\\s*)|http(s*)://\\S+|[^A-Za-z ]+'\n",
        "    replace_with_space = '\\s...\\s'\n",
        "\n",
        "    # removes tweeting at someone\n",
        "    df['cleaned_tweet'] = df['raw_tweet'].replace(regex=True, to_replace=r'@\\S+', value=r'')\n",
        "     # turns elipses into just a space\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'\\s...\\s', value=r' ')\n",
        "    # for some reason &'s show up before hashtags, so remove those specific &s\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'&#', value=r'')\n",
        "    # remove the RT that comes before the retweet\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'RT(\\s*)', value=r'')\n",
        "    # remove any links to websites\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'http(s*)://\\S+', value=r'')\n",
        "    # remove any non letter or space\n",
        "    df['cleaned_tweet'].replace(regex=True, inplace=True, to_replace=r'[^A-Za-z ]+',value=r'')\n",
        "    # put it all to lower case\n",
        "    df['cleaned_tweet'] = df['cleaned_tweet'].str.lower()\n",
        "    return  df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfzNJNUDiaA6",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test Set Generation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbM_EIR01FOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_test(df, train_pct):\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    train_cutoff = math.floor(train_pct * len(df))\n",
        "    train, test = df[:train_cutoff], df[train_cutoff:]\n",
        "    return train, test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqDUcbgIh7Wh",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvE84MHmjmlP",
        "colab_type": "text"
      },
      "source": [
        "## Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cRvjPWAXC6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_crowd_flower = load_dataset('crowd_flower')\n",
        "df_data_world = load_dataset('data_world')\n",
        "df_harassment = load_dataset('harassment')\n",
        "df_olid = load_dataset('olid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VHAsdBrioZ1",
        "colab_type": "text"
      },
      "source": [
        "## Clean & Parse Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my07fvxjkP-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desired_cols = [\"is_hate_speech\", \"cleaned_tweet\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_buCpZjO7Bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_crowd_flower_cleaned = clean_dataframe(parse_crowd_flower(df_crowd_flower))[desired_cols]\n",
        "df_data_world_cleaned = clean_dataframe(parse_data_world(df_data_world))[desired_cols]\n",
        "df_harassment_cleaned = clean_dataframe(parse_harassment(df_harassment))[desired_cols]\n",
        "df_olid_cleaned = clean_dataframe(parse_olid(df_olid))[desired_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDs4LVJvoRkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_crowd_flower_cleaned.sample(5)\n",
        "df_data_world_cleaned.sample(5)\n",
        "df_harassment_cleaned.sample(5)\n",
        "df_olid_cleaned.sample(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX4xZyiLjz1e",
        "colab_type": "text"
      },
      "source": [
        "## Make Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roWR2Yvgmq6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PERCENTAGE = 0.80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVklQZl177FH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cf_train, cf_test = make_train_test(df_crowd_flower_cleaned, TRAIN_PERCENTAGE)\n",
        "dw_train, dw_test = make_train_test(df_data_world_cleaned, TRAIN_PERCENTAGE)\n",
        "harass_train, harass_test = make_train_test(df_harassment_cleaned, TRAIN_PERCENTAGE)\n",
        "olid_train, olid_test = make_train_test(df_olid_cleaned, TRAIN_PERCENTAGE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "powMfxnJkX0C",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaR9yn00kcU7",
        "colab_type": "text"
      },
      "source": [
        "## Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzaPRGIg3RqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    text = \" \".join(text.split())\n",
        "    buffer = \"\"\n",
        "    tokens = []\n",
        "    for c in text:\n",
        "        if c != ' ' and c not in string.punctuation:\n",
        "            buffer+=c\n",
        "        elif c != ' ' and c in string.punctuation:\n",
        "            if len(buffer) != 0: tokens.append(buffer)\n",
        "            tokens.append(c)\n",
        "            buffer = \"\"\n",
        "        else:\n",
        "            if len(buffer) != 0: tokens.append(buffer)\n",
        "            buffer = \"\"\n",
        "    if len(buffer) != 0: tokens.append(buffer)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90FemdrZTvFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_examples_from_df(dframe, row_name, label_name):\n",
        "    D = []\n",
        "    y = []\n",
        "    for idx, row in dframe.iterrows():\n",
        "        d = row[row_name] \n",
        "        label = row[label_name]\n",
        "        tokens = tokenize(d)\n",
        "        D.append(tokens)\n",
        "        y.append(label)\n",
        "    return D, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kapGHUyoBs-",
        "colab_type": "text"
      },
      "source": [
        "## Doc2Vec Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk24qJwRqp-b",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec Vector Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTR7p7udqwjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: Our tokenized document list, tag prefix for labeling (either \"TRAIN\" or \"TEST\")\n",
        "# Returns tagged list of documents for Doc2Vec model to use\n",
        "def tag_docs(D, tag_prefix):\n",
        "    tagged = []\n",
        "    for idx, tweet in enumerate(D):\n",
        "        tag = tag_prefix + '_' + str(idx)\n",
        "        tagged.append(TaggedDocument(tweet, [tag]))\n",
        "    return tagged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSEXKCohrQBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: Doc2Vec model, data set (should use validation data here probably)\n",
        "# Does not return anything, just trains the model and tunes params\n",
        "def train_doc2vec(model, tagged_docs):\n",
        "    for epoch in range(30):\n",
        "        model.train(utils.shuffle([x for x in tagged_docs]), total_examples=len(tagged_docs), \n",
        "                    epochs=1)\n",
        "        model.alpha -= 0.002\n",
        "        model.min_alpha = model.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehl1XqucrPrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: Doc2Vec model, length of example vectors, tag of either \"TRAIN\" or \"TEST\"\n",
        "# Returns a np matrix of document vectors, to input into Logistic Regression classifier\n",
        "def get_vectors(model, vector_length, tag_type):\n",
        "    vectors = np.zeros((model.corpus_count, vector_length))\n",
        "    for i in range(model.corpus_count):\n",
        "        prefix = tag_type + '_' + str(i)\n",
        "        vectors[i] = model.docvecs[prefix]\n",
        "    return vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlXHxfgq874_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Doc2Vec Neural Nets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slJayfOq8_zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FF NETWORK MODEL  \n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(100, 100)\n",
        "        self.l2 = torch.nn.Linear(100, 25)\n",
        "        self.l3 = torch.nn.Linear(25, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out1 = self.l1(x)\n",
        "        out2 = self.l2(out1)\n",
        "        out3 = self.l3(F.relu(out2))\n",
        "        y_pred = self.sigmoid(out3)\n",
        "        return y_pred\n",
        "\n",
        "# CNN MODEL\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 100, kernel_size=3)\n",
        "        self.conv2 = torch.nn.Conv2d(100, 8, kernel_size=3)\n",
        "        self.l1 = torch.nn.Linear(288, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out1 = F.relu(self.conv1(x))\n",
        "        out2 = F.relu(self.conv2(out1))\n",
        "        # reshape\n",
        "        batch_size = out2.size(0)\n",
        "        out2 = out2.view(batch_size, -1)\n",
        "        y_pred = self.sigmoid(self.l1(out2))\n",
        "        return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfI0JQTYn8ph",
        "colab_type": "text"
      },
      "source": [
        "### Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3swZMCf9Ypo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs, X, y):\n",
        "    # initialize weights and bias\n",
        "    for m in model.modules():\n",
        "        if isinstance(m,torch.nn.Linear):\n",
        "            torch.nn.init.normal(m.weight, mean=0, std=0.1)\n",
        "            torch.nn.init.constant(m.bias,0.1)\n",
        "        if isinstance(m, torch.nn.Conv2d):\n",
        "            torch.nn.init.normal(m.weight, mean=0, std=0.1)\n",
        "    \n",
        "    best_acc = -1\n",
        "    f1 = -1\n",
        "    # train model\n",
        "    for epoch in range(num_epochs):\n",
        "        y_pred = model(X)\n",
        "        loss = criterion(y_pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        acc,_ = compute_NN_accuracy(y_pred, y)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            f1 = calculate_NN_f1(y_pred, y)\n",
        "    \n",
        "    # training accuracy after last epoch\n",
        "    return best_acc, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79MwkG1qdwt",
        "colab_type": "text"
      },
      "source": [
        "### Run Doc2Vec Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9vxCK01qiwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INITIALIZE DOC2VEC, CREATE VECTORS\n",
        "\n",
        "# GET TOKENIZED DATA, TAG DATA\n",
        "D_train,y_train = construct_examples_from_df(harass_train, \"cleaned_tweet\", \"is_hate_speech\")\n",
        "tagged_docs = tag_docs(D_train, \"TRAIN\")\n",
        "\n",
        "# INITIALIZE DOC2VEC MODEL\n",
        "doc_model = Doc2Vec(dm=0, vector_size=100, window=7, negative=5, min_count=2, alpha=0.1)\n",
        "doc_model.build_vocab([x for x in tqdm(tagged_docs)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M2lLBabRCsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAINING\n",
        "\n",
        "# TRAIN MODEL, VECTORIZE DATA\n",
        "doc_model.train(utils.shuffle([x for x in tagged_docs]), total_examples=len(tagged_docs), \n",
        "                epochs=15)\n",
        "X_train_vectors = get_vectors(doc_model, 100, \"TRAIN\")\n",
        "X_train_vectors = X_train_vectors.reshape([len(D_train), 1, 10, 10])\n",
        "X_train_tensor = torch.from_numpy(X_train_vectors)\n",
        "X_train_tensor = X_train_tensor.float()\n",
        "y_train_tensor = torch.FloatTensor(y_train)\n",
        "y_train_tensor = y_train_tensor.view(y_train_tensor.size(0), -1)\n",
        "\n",
        "# LOGISITIC REGRESSION CLASSIFIER\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(X_train_vectors, y_train)\n",
        "logreg = logreg.fit(X_train_vectors, y_train)\n",
        "y_pred = logreg.predict(X_train_vectors)\n",
        "\n",
        "# EVAULATE F1 SCORE, ACCURACY, CONFUSION MATRIX (FOR LOGISTIC REGRESSION)\n",
        "f1 = calculate_f1(y_train, y_pred)\n",
        "acc = compute_accuracy(y_pred, y_train)\n",
        "plot_confusion_matrix(y_train, y_pred, title=\"Training Data 1\", cmap=newcmp)\n",
        "print(f1)\n",
        "print(acc)\n",
        "\n",
        "# CONVOLUTIONAL NEURAL NET CLASSIFIER\n",
        "NN_model = Net()\n",
        "LCE_criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(NN_model.parameters(), lr=0.01)\n",
        "num_epochs = 100\n",
        "NN_acc,NN_f1 = train_model(NN_model, LCE_criterion, optimizer, num_epochs, X_train_tensor, \n",
        "                           y_train_tensor)\n",
        "\n",
        "print(NN_acc)\n",
        "print(NN_f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NoSEWzWLeOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TESTING\n",
        "\n",
        "# GET TOKENIZED DATA, TAG DATA\n",
        "D_test,y_test = construct_examples_from_df(harass_test, \"cleaned_tweet\", \"is_hate_speech\")\n",
        "tagged_docs_test = tag_docs(D_test,\"TEST\")\n",
        "\n",
        "# INITIALIZE DOC2VEC MODEL\n",
        "doc_test_model = Doc2Vec(dm=0, vector_size=100, window=7, negative=5, min_count=2, alpha=0.1)\n",
        "doc_test_model.build_vocab([x for x in tqdm(tagged_docs_test)])\n",
        "doc_test_model.train(utils.shuffle([x for x in tagged_docs_test]), \n",
        "                     total_examples=len(tagged_docs_test), epochs=15)\n",
        "\n",
        "# LOGISTIC REGRESSION\n",
        "X_test_vectors = get_vectors(doc_test_model, 100, \"TEST\")\n",
        "y_pred_test = logreg.predict(X_test_vectors)\n",
        "f1 = calculate_f1(y_test, y_pred_test)\n",
        "acc = compute_accuracy(y_pred_test, y_test)\n",
        "plot_confusion_matrix(y_test, y_pred_test, title=\"Training Data 1\", cmap=newcmp)\n",
        "\n",
        "print(f1)\n",
        "print(acc)\n",
        "\n",
        "# NEURAL NET\n",
        "X_train_vectors = X_train_vectors.reshape([len(D_test), 1, 10, 10])\n",
        "X_test_tensor = torch.from_numpy(X_test_vectors)\n",
        "X_test_tensor = X_test_tensor.float()\n",
        "y_test_tensor = torch.FloatTensor(y_test)\n",
        "y_test_tensor = y_test_tensor.view(y_test_tensor.size(0),-1)\n",
        "test_output = NN_model(X_test_tensor)\n",
        "acc_test,predictions = compute_NN_accuracy(test_output, y_test_tensor)\n",
        "f1_test = calculate_NN_f1(test_output, y_test_tensor)\n",
        "plot_confusion_matrix(y_test, predictions, \"DataWorld Test\", cmap=newcmp)\n",
        "\n",
        "print(acc_test)\n",
        "print(f1_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7dHwk43oGxw",
        "colab_type": "text"
      },
      "source": [
        "## TFIDF Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HSBUuT43a5w",
        "colab_type": "text"
      },
      "source": [
        "### TFIDF Feature Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpWq-aExFjZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vocabulary(D):\n",
        "    vocab = set()\n",
        "    vocab.add(\"<unk>\")\n",
        "    seen = set() \n",
        "    for doc in D:\n",
        "        for t in doc:\n",
        "            if t in seen:\n",
        "                vocab.add(t)\n",
        "            else:\n",
        "                # add to seen set when we see it first time, when we encounter again \n",
        "                # we add to vocab\n",
        "                seen.add(t)\n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0igjWZxL4-Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_idf(D, vocab):\n",
        "    unk = \"<unk>\"\n",
        "    numerator = len(D)\n",
        "    idf = {v:0 for v in vocab}\n",
        "    for doc in D:\n",
        "        doc = set(doc)\n",
        "        unk_used = False\n",
        "        for t in doc:\n",
        "            if t in vocab:\n",
        "                idf[t] += 1\n",
        "            elif not(unk_used):\n",
        "                idf[unk] += 1\n",
        "                unk_used = True\n",
        "    for feat in idf.keys():\n",
        "        idf[feat] = math.log(numerator/idf[feat])\n",
        "    return idf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW-KI7Yd3h2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFIDFFeaturizer(object):\n",
        "    def __init__(self, idf):\n",
        "        self.idf = idf\n",
        "    \n",
        "    def convert_document_to_feature_dictionary(self, doc, vocab):\n",
        "        unk = \"<unk>\"\n",
        "        doc_dict = {token:0 for token in vocab}\n",
        "        for t in doc:\n",
        "            if t in vocab:\n",
        "                doc_dict[t] = doc_dict.get(t, 0) + 1\n",
        "            else:\n",
        "                doc_dict[unk] = doc_dict.get(unk, 0) + 1\n",
        "        \n",
        "        for token in doc_dict.keys():\n",
        "            doc_dict[token] *= self.idf[token]\n",
        "        \n",
        "        return doc_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYao2bgQXsJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_features(D, featurizer, vocab): \n",
        "    X = []\n",
        "    for doc in D: \n",
        "        X.append(featurizer.convert_document_to_feature_dictionary(doc, vocab))\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV89MYyU4lJD",
        "colab_type": "text"
      },
      "source": [
        "### Run TFIDF-Features Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0nTNI9YKdeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN\n",
        "\n",
        "# GET TOKENIZED DATA AND VOCAB\n",
        "D_train,y_train = construct_examples_from_df(olid_train, \"cleaned_tweet\", \"is_hate_speech\")\n",
        "vocab = get_vocabulary(D_train)\n",
        "\n",
        "# GET TFIDF-FEATURIZED EXAMPLES\n",
        "tfidf = TFIDFFeaturizer(compute_idf(D_train, vocab))\n",
        "X_train = convert_to_features(D_train, tfidf, vocab)\n",
        "\n",
        "# SVM CLASSIFIER\n",
        "vectorizer = DictVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "svm = LinearSVC(loss='hinge', max_iter=10000)\n",
        "svm.fit(X_train_vect, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IryprMSM0yf9",
        "colab_type": "code",
        "outputId": "95822d7e-fd15-415f-8512-9110a3961410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "# TEST\n",
        "\n",
        "D_test,y_test = construct_examples_from_df(dw_test, \"cleaned_tweet\", \"is_hate_speech\")\n",
        "X_test = convert_to_features(D_test, tfidf, vocab)\n",
        "y_pred_test = svm.predict(vectorizer.fit_transform(X_test))\n",
        "\n",
        "# EVAULATE F1 SCORE, ACCURACY, CONFUSION MATRIX OF TESTING DATA\n",
        "f1_test = calculate_f1(y_test, y_pred_test)\n",
        "acc_test = compute_accuracy(y_pred_test, y_test)\n",
        "plot_confusion_matrix(y_test, y_pred_test, title=\"DataWorld Test\", cmap=newcmp)\n",
        "print(f1_test)\n",
        "print(acc_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10005726229163753\n",
            "0.38297013720742534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEOCAYAAACpc6r8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8M0S9P8B8hvD+4k8Ud8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bZMjf9L4EaR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Evaluation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZjT9VlOoV0p",
        "colab_type": "text"
      },
      "source": [
        "### TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W03QceYx4Hhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_f1(y_gold, y_model):\n",
        "    num_pred_positive = 1e-5\n",
        "    num_positive = 1e-5\n",
        "    for label in y_model:\n",
        "        if label == 1:\n",
        "            # count total predicted num of positives\n",
        "            num_pred_positive += 1\n",
        "    for label in y_gold:\n",
        "        if label == 1:\n",
        "            # count total actual num of positives\n",
        "            num_positive += 1\n",
        "    # total true predicted positives\n",
        "    num_true = sum(int((y1 == 1 and y2 == 1)) for y1,y2 in list(zip(y_gold,y_model)))\n",
        "    precision = num_true / num_pred_positive\n",
        "    recall = num_true / num_positive\n",
        "    F1 = 2*(precision*recall)/(precision+recall+1e-5)\n",
        "    return F1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO2Sa2JPnRAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(y_pred, y_gold):\n",
        "    num_correct = 0\n",
        "    num_examples = len(y_gold)\n",
        "    for i in range(num_examples):\n",
        "        if y_pred[i] == y_gold[i]:\n",
        "            num_correct += 1\n",
        "    return num_correct/num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k91y4ZdEoYiO",
        "colab_type": "text"
      },
      "source": [
        "### Doc2Vec NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5aIQTd99ouk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_NN_accuracy(y_pred, y_true):\n",
        "    num_correct = 0\n",
        "    num_instances = y_true.size(0)\n",
        "    predictions = []\n",
        "    for i in range(num_instances):\n",
        "        curr_pred = y_pred[i][0]\n",
        "        curr_true = y_true[i][0]\n",
        "        y_est = 1 if curr_pred > 0.5 else 0\n",
        "        predictions.append(y_est)\n",
        "        if y_est == curr_true:\n",
        "            num_correct += 1\n",
        "    return (num_correct / num_instances), predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyDmP7a-ROdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_NN_f1(y_pred, y_true):\n",
        "    num_pred_positive = 1e-5\n",
        "    num_positive = 1e-5\n",
        "    num_true = 1e-5\n",
        "    num_instances = y_true.size(0)\n",
        "    for i in range(num_instances):\n",
        "        curr_pred = y_pred[i][0]\n",
        "        curr_true = y_true[i][0]\n",
        "        y_est = 1 if curr_pred > 0.5 else 0\n",
        "        if y_est == 1:\n",
        "            # count total predicted num of positives\n",
        "            num_pred_positive += 1\n",
        "        if curr_true == 1:\n",
        "            num_positive += 1\n",
        "        if curr_true == 1 and y_est == 1:\n",
        "            # count total true predicted positives\n",
        "            num_true += 1 \n",
        "        \n",
        "    precision = num_true / num_pred_positive\n",
        "    recall = num_true / num_positive\n",
        "    F1 = 2*(precision*recall)/(precision+recall+1e-5)\n",
        "    return F1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cojJha-KpZIA",
        "colab_type": "text"
      },
      "source": [
        "## Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqtgPNmkZphY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE COLORMAP\n",
        "N = 256\n",
        "vals = np.ones((N, 4))\n",
        "vals[:, 0] = np.linspace(0.113, 1, N)\n",
        "vals[:, 1] = np.linspace(0.631, 1, N)\n",
        "vals[:, 2] = np.linspace(0.953, 1, N)\n",
        "newcmp = ListedColormap(vals[::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppC2LMjApe2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs: true labels, predicted labels, matrix title, matrix colormap\n",
        "# Returns the figure, shows the figure automatically when called\n",
        "def plot_confusion_matrix(y_true, y_pred, title, cmap):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.set(title=title,ylabel='True Label',xlabel='Predicted Label')\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt), fontweight='bold',\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwp9p5sNWizB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input: list of F1 scores, list of datasets corresponding to F1 scores, graph title\n",
        "# Returns graph, must call plt.show() after run to show the graph\n",
        "\n",
        "def plot_scores(f1_scores, data_titles, title):\n",
        "    TEAL = (0.113, 0.631, 0.953, 1.0)\n",
        "    # how many different datasets are we comparing?\n",
        "    idx = np.arange(len(data_titles))\n",
        "    plt.ylim((0.2,0.5))\n",
        "    # plot bar for each test and its F1 score\n",
        "    plt.bar(idx,f1_scores,width=0.4,color=TEAL)\n",
        "    plt.xlabel('Training Set')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.title(title)\n",
        "    plt.xticks(idx, data_titles, fontsize=5, rotation=45)\n",
        "    for i,v in enumerate(f1_scores):\n",
        "        plt.text(i, v+0.01, str(v), color=TEAL, ha='center', fontweight='bold')\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1c06oRAKwtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [\"DataWorld\", \"OLID\", \"Golbeck\", \"Founta\"]\n",
        "title = \"Average Test Accuracy vs. Training Data\"\n",
        "avg_acc_scores = [0.625, 0.667, 0.655, 0.640]\n",
        "#plot_scores(avg_acc_scores,data,title)\n",
        "avg_f1_score = [0.246, 0.464, 0.243, 0.271]\n",
        "title2 = \"Average F1 Score vs. Training Data\"\n",
        "plot_scores(avg_f1_score, data, title2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}